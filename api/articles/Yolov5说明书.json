{"title":"YOLOv5说明书","uid":"4eb946cc0edf20ceda9a686ce0927f5a","slug":"Yolov5说明书","date":"2022-05-07T03:54:21.000Z","updated":"2022-06-06T16:32:40.579Z","comments":true,"path":"api/articles/Yolov5说明书.json","keywords":null,"cover":[],"content":"<p>$\\qquad$YOLO 的全称是 You Only Look Once，指只需要浏览一次就可以识别出图中的物体的类别和位置。YOLOv5 是由 Ultralytics LLC 公司于 2020 年 5 月所提出，其图像推理速度最快达 0.007 s，即每秒可处理 140 帧，满足视频图像实时检测需求，同时结构更为小巧。</p>\n<p>$\\qquad$本文介绍YOLOv5的打开方式及一些注意事项。</p>\n<img src=\"/images/ML/2/1.jpg\" style=\"zoom:20%;\">\n\n<span id=\"more\"></span>\n\n<br>\n\n<hr>\n<h2><span id=\"preface\">⨇ Preface</span></h2><p>$\\qquad$五一前参加了一个名叫泰迪杯的比赛，名字听着像个野鸡比赛，其实是个机器学习比赛，也办了挺多届。这学期有选机器学习（大半个学期过去了，我只会KNN和逻辑斯蒂回归）和数据挖掘（老师讲的挺认真，但我经常上课mo鱼），因此就和同学报名参加了。</p>\n<p>$\\qquad$我们选择的是农田害虫识别赛题，顾名思义，就是给出害虫照片集与相应的害虫标签及位置框坐标，需要我们训练模型来识别图片中的害虫位置与种类。第一次参加机器学习比赛，没什么经验，基础也不太行，所以我们主要的时间都花在数据集处理上面了。训练模型直接采用了比赛培训中讲的YOLOv5，在浏览了大量博客之后算是上手了，本文就分享一下使用方式以及一些tips。</p>\n<hr>\n<br>\n\n<center>⚠️下文中所有的相对路径都默认在下载的文件夹yolov5/下</center>\n<br>\n\n<hr>\n<h2><span id=\"ω\">Ω</span></h2><ol>\n<li><p>首先从github上将这个官方仓库clone下来（或直接在<a href=\"https://github.com/ultralytics/yolov5\">官网</a>Code→Download zip）</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/ultralytics/yolov5.git</span><br></pre></td></tr></table></figure>\n\n<p>速度太慢的话就用镜像</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://gitee.com/monkeycc/yolov5.git</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>在下载的文件夹中打开terminal，安装运行环境所需要的依赖包</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>创建训练配置文件：data&#x2F;*.yaml ，格式示例如下</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># path of training and validation set</span></span><br><span class=\"line\"><span class=\"attr\">train:</span> <span class=\"string\">dataset/images/train</span></span><br><span class=\"line\"><span class=\"attr\">val:</span> <span class=\"string\">dataset/images/val</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Classes</span></span><br><span class=\"line\"><span class=\"attr\">nc:</span> <span class=\"number\">8</span>  <span class=\"comment\"># number of classes</span></span><br><span class=\"line\"><span class=\"attr\">names:</span> [<span class=\"string\">&#x27;6&#x27;</span>,<span class=\"string\">&#x27;apple&#x27;</span>,<span class=\"string\">&#x27;7&#x27;</span>,<span class=\"string\">&#x27;dog&#x27;</span>,<span class=\"string\">&#x27;cat&#x27;</span>,<span class=\"string\">&#x27;485&#x27;</span>,<span class=\"string\">&#x27;pear&#x27;</span>,<span class=\"string\">&#x27;673&#x27;</span>] </span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>train和val是训练集和验证集（自行划分）的图片文件夹目录，相对路径和绝对路径均可</li>\n<li>nc是类数，names则是包含所有类名的列表</li>\n</ul>\n</li>\n<li><p>使用预训练权重可以缩短训练时间，并提高训练精度，预训练规模越大，训练精度相对更高，但检测时间更长.</p>\n<p> <a href=\"https://github.com/ultralytics/yolov5/releases\">在此</a>下载预训练权重，并将下载的pt文件置于models&#x2F;下，一般选择yolov5s.pt即可，权重大小即代表了权重规模</p>\n<img src=\"/images/ML/2/2.png\" style=\"zoom:50%;\">\n</li>\n<li><p>下载的预训练权重为yolov5*.pt，那么就修改相对应的models&#x2F;yolov5*.yaml文件，只需将其中的nc改为你自己的类数即可</p>\n</li>\n<li><p>训练数据集一般存放于dataset&#x2F;，且dataset的文件树结构需要如下所示</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dataset</span><br><span class=\"line\">├── images</span><br><span class=\"line\">│   ├── train</span><br><span class=\"line\">│   └── val</span><br><span class=\"line\">└── labels</span><br><span class=\"line\">    ├── train</span><br><span class=\"line\">    └── val</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>dataset下分为两个文件夹images&#x2F;和labels&#x2F;，前者存放图像，后者存放每张图像的txt文件</p>\n</li>\n<li><p>txt中存放图片中含有的类别和相应的方框坐标，格式为</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class_num box中心横坐标与图像宽度比值 box中心纵坐标与图像高度比值 box宽度与图像宽度比值 box高度与图像高度比值</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>class_num是【3】中yaml文件里的names索引（从0开始计数），如class_num&#x3D;2，那么表示的就是‘7’</p>\n</li>\n<li><p>坐标的原点在图像的左上角，向右是$x$轴正方向，向下是$y$轴正方向，坐标单位是像素</p>\n</li>\n<li><p>$class\\_num\\in[0,nc-1]$，后面四个值均$\\in (0,1)$</p>\n</li>\n<li><p>一个识别目标一行，<strong>若该图片中没有目标则为空</strong>即可</p>\n<img src=\"/images/ML/2/3.png\" style=\"zoom:50%;\"></li>\n</ul>\n</li>\n<li><p>images&#x2F;和labels&#x2F;下又分别含有两个文件夹，训练集train&#x2F;和验证集val&#x2F;</p>\n</li>\n<li><p>images&#x2F;train&#x2F;和labels&#x2F;train&#x2F;，images&#x2F;val&#x2F;和labels&#x2F;val&#x2F; 下的文件除后缀外<strong>数量</strong>和<strong>文件名</strong>必须完全一致，即图片和txt必须一一对应（没有目标也必须有相应的txt），否则训练时会报错</p>\n</li>\n</ul>\n</li>\n<li><p>如果想手动画框并生成YOLO格式的txt，可以使用labelimg工具</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install labelimg</span><br></pre></td></tr></table></figure>\n\n<p>安装完成后直接在terminal中输入labelimg即可使用（注意使用时先将【PascalVOC】格式 改为【YOLO】格式）</p>\n</li>\n<li><p>train.py是训练代码，其中只需修改<code>parse_opt(known=False)</code> 函数的定义部分</p>\n<ul>\n<li><p><code>--weights</code>部分是预训练权重的地址，也可以选择上一次训练中效果最好的权重：runs&#x2F;train&#x2F;exp$n$&#x2F;weights&#x2F;best.pt</p>\n</li>\n<li><p><code>--cfg</code>是【3】中的yaml文件地址</p>\n</li>\n<li><p><code>--data</code>是【5】中的yaml文件地址</p>\n</li>\n<li><p><code>--epochs</code>可以设置训练的轮数，一般设置300轮较为合适</p>\n</li>\n<li><p><code>--resume</code>将<code>default</code>改为<code>True</code>可以继续上一次未完成的训练（如果前一次训练意外中断或者人为终止），此时将忽略<code>--weights</code>设置的预训练权重</p>\n</li>\n<li><p>其他一般无需修改</p>\n<img src=\"/images/ML/2/4.png\" style=\"zoom:50%;\"></li>\n</ul>\n</li>\n<li><p>用训练权重来识别图片（一般将需要识别的图片放置在data&#x2F;images&#x2F;下）</p>\n<ul>\n<li><p>生成识别结果的图片和txt</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python detect.py --weights path_weight --source path_images --device cpu --save-txt</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>仅生成识别结果图片</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python detect.py --weights path_weight --source path_iamges --device cpu --img 640</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>其中<code>path_weight</code>是权重的地址，<code>path_images</code>是识别图片所在文件夹地址</p>\n</li>\n<li><p>如果可以调用GPU，请将<code>--device cpu</code>去掉</p>\n</li>\n<li><p>Exp：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python detect.py --weights runs/train/exp13/weights/best.pt --source data/images/ --device cpu --save-txt</span><br></pre></td></tr></table></figure></li>\n</ul>\n</li>\n<li><p>runs&#x2F;train&#x2F;下存放着每一次的训练结果；runs&#x2F;detect&#x2F;下存放着每一次的识别结果. exp$n$表示第$n$次结果.</p>\n</li>\n</ol>\n<hr>\n<h3><span id=\"︎-training-︎\">⚡︎ training ⚡︎</span></h3><img src=\"/images/ML/2/5.jpeg\" style=\"zoom:70%;\">\n\n<br>\n\n<h3><span id=\"outcome\">≫ Outcome ≪</span></h3><img src=\"/images/ML/2/6.jpg\" style=\"zoom:50%;\">","text":"$\\qquad$YOLO 的全称是 You Only Look Once，指只需要浏览一次就可以识别出图中的物体的类别和位置。YOLOv5 是由 Ultralytics LLC 公司于 2020 年 5 月所提出，其图像推理速度最快达 0.007 s，即每秒可处理 140 帧，满...","link":"","photos":[],"count_time":{"symbolsCount":"3k","symbolsTime":"3 mins."},"categories":[{"name":"Machine Learning","slug":"Machine-Learning","count":3,"path":"api/categories/Machine-Learning.json"}],"tags":[{"name":"走码观花","slug":"走码观花","count":15,"path":"api/tags/走码观花.json"},{"name":"python","slug":"python","count":11,"path":"api/tags/python.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\"><span class=\"toc-text\">⨇ Preface</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\"><span class=\"toc-text\">Ω</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\"><span class=\"toc-text\">⚡︎ training ⚡︎</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\"><span class=\"toc-text\">≫ Outcome ≪</span></a></li></ol></li></ol>","author":{"name":"Starlit Rover","slug":"blog-author","avatar":"https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcQWu4nWh5NV26rlAS5lR23iaundn5IVlV3EpYGNAdtnMObooQnk","link":"/","description":"Stroll in the starlit firmament~","socials":{"github":"https://github.com/StarlitRover","twitter":"https://twitter.com/Starlit_Rover","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"steam":{"icon":"/images/aurora/steam.svg","link":"https://steamcommunity.com/id/starlitrover/"}}}},"mapped":true,"prev_post":{"title":"<00> REG2NFA","uid":"6fcdc9dd323137269ea9dcabb8b1efc8","slug":"00-REG2NFA","date":"2022-05-09T15:49:12.000Z","updated":"2022-05-17T07:57:50.980Z","comments":true,"path":"api/articles/00-REG2NFA.json","keywords":null,"cover":[],"text":"$\\qquad$本文借助transitions库基于逆波兰表示法（Reverse Polish Notation，RPN）实现了正则表达式转NFA，并画出相关的状态转移图。 ∅ Transitions库介绍$\\qquad$引用官网中的一句话“They say a good exa...","link":"","photos":[],"count_time":{"symbolsCount":"5.5k","symbolsTime":"5 mins."},"categories":[{"name":"编译原理","slug":"编译原理","count":7,"path":"api/categories/编译原理.json"}],"tags":[{"name":"走码观花","slug":"走码观花","count":15,"path":"api/tags/走码观花.json"},{"name":"python","slug":"python","count":11,"path":"api/tags/python.json"}],"author":{"name":"Starlit Rover","slug":"blog-author","avatar":"https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcQWu4nWh5NV26rlAS5lR23iaundn5IVlV3EpYGNAdtnMObooQnk","link":"/","description":"Stroll in the starlit firmament~","socials":{"github":"https://github.com/StarlitRover","twitter":"https://twitter.com/Starlit_Rover","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"steam":{"icon":"/images/aurora/steam.svg","link":"https://steamcommunity.com/id/starlitrover/"}}}}},"next_post":{"title":"Bison^Flex=语法分析生成中","uid":"1ebcc2044e1859de323771c4cf459a30","slug":"Bison-Flex-语法分析生成中","date":"2022-05-05T14:23:51.000Z","updated":"2022-05-22T11:37:41.903Z","comments":true,"path":"api/articles/Bison-Flex-语法分析生成中.json","keywords":null,"cover":[],"text":"$\\qquad$上古时代的时候（前一段时间参加了些些小竞赛，状态有点迷糊，五一又浪里个浪，所以…虽迟但到！），我们有讲解过借助Flex实现SysY词法分析。词法分析是编译的第一阶段，仅仅只是将代码进行切块归类，得到的只是些零散的tokens。现在我们进入第二阶段，对这些token...","link":"","photos":[],"count_time":{"symbolsCount":"46k","symbolsTime":"42 mins."},"categories":[{"name":"编译原理","slug":"编译原理","count":7,"path":"api/categories/编译原理.json"}],"tags":[{"name":"走码观花","slug":"走码观花","count":15,"path":"api/tags/走码观花.json"}],"author":{"name":"Starlit Rover","slug":"blog-author","avatar":"https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcQWu4nWh5NV26rlAS5lR23iaundn5IVlV3EpYGNAdtnMObooQnk","link":"/","description":"Stroll in the starlit firmament~","socials":{"github":"https://github.com/StarlitRover","twitter":"https://twitter.com/Starlit_Rover","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"steam":{"icon":"/images/aurora/steam.svg","link":"https://steamcommunity.com/id/starlitrover/"}}}}}}